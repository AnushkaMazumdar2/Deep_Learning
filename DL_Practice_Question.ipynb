{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzC3GAmrco3tdf53RWRxJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnushkaMazumdar2/Deep_Learning/blob/main/DL_Practice_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assume we are attempting to train a back-propagation neural network with two hidden layers and a single node in each layer. Let us assume that the activation function is sigmoid function and all the weights and biases are initially set to w=1, b= -0.5, respectively. Compute the forward-pass output for input 0.5. Let the input 0.5 correspond to the target output y =1. Demonstrate the process of learning using Gradient Descent at for 2 iterations to obtain the target 1 for the input 0.5**\n",
        "\n",
        "\n",
        "1. **Initialization**: Initialize the weights and biases for each layer. Since we have two hidden layers and one output layer, we'll have three sets of weights and biases.\n",
        "\n",
        "   - Weights: \\(w_1, w_2, w_3 = 1, 1, 1\\)\n",
        "   - Biases: \\(b_1, b_2, b_3 = -0.5, -0.5, -0.5\\)\n",
        "\n",
        "2. **Forward Pass**: Compute the output of each layer using the sigmoid activation function.\n",
        "\n",
        "   - **Input Layer**: The input is \\(x = 0.5\\).\n",
        "   - **First Hidden Layer**:\n",
        "     - z_1 = w_1 X x_1 + b_1 = (1 * 0.5) - 0.5 = 0\n",
        "     - a_1 = sigmoid(z_1) = sigmoid(0) = 1/(1+e^0) = 0.5\n",
        "   - **Second Hidden Layer**:\n",
        "     - z_2 = w_2 X a_1 + b_2 = (1 * 0.5) - 0.5 = 0\n",
        "     - a_2 = sigmoid(z_2) = sigmoid(0) = 1/(1+e^0) = 0.5\n",
        "   - **Output Layer**:\n",
        "     - z_3 = w_3 X a_2 + b_3 = (1 * 0.5) - 0.5 = 0\n",
        "     - \\(a_3 = \\sigma(z_3) = \\sigma(0) = 1/(1+e^0) = 0.5\n",
        "\n",
        "3. **Error Calculation**: Compute the error between the output and the target.\n",
        "\n",
        "   - Error: E = 1/2(y - a_3)^2 = 1/2(1 - 0.5)^2 = 0.125\n",
        "\n",
        "4. **Backpropagation (Gradient Descent)**: Update the weights and biases using the gradient descent algorithm.\n",
        "\n",
        "   - **Output Layer**:\n",
        "     - delta_3 = (a_3 - y) * sigma'(z_3) = (0.5 - 1) * sigma'(0) = -0.125 * 0.25 = -0.03125\n",
        "     - w_3 = w_3 - alpha * delta_3 * a_2 = 1 - 0.1 * (-0.03125) * 0.5 = 1.0015625\n",
        "     - b_3 = b_3 - alpha * delta_3 = -0.5 - 0.1 * (-0.03125) = -0.496875\n",
        "   - **Second Hidden Layer**:\n",
        "     - delta_2 = delta_3 * w_3 * \\sigma'(z_2) = -0.03125 * 1.0015625 * sigma'(0) = -0.03125 * 1.0015625 * 0.25 = -0.0078125\\)\n",
        "     - w_2 = w_2 - alpha * delta_2 * a_1 = 1 - 0.1 * (-0.0078125) * 0.5 = 1.000390625\n",
        "     - b_2 = b_2 - alpha * delta_2 = -0.5 - 0.1 * (-0.0078125) = -0.49921875\n",
        "   - **First Hidden Layer**:\n",
        "     - delta_1 = delta_2 * w_2 * sigma'(z_1) = -0.0078125 * 1.000390625 * sigma'(0) = -0.0078125 * 1.000390625 * 0.25 = -0.001953125\n",
        "     - w_1 = w_1 - alpha * delta_1 * x = 1 - 0.1 * (-0.001953125) * 0.5 = 1.00009765625\n",
        "     - b_1 = b_1 - alpha * delta_1 = -0.5 - 0.1 * (-0.001953125) = -0.499804\n",
        "\n",
        "5. **Repeat**: Repeat steps 2-4 for two iterations\n",
        "\n",
        "6. **Final Output**: After 2 iterations, the final output is a_3 = 0.5, which is not equal to the target output y = 1. The error is E = 0.125.\n",
        "\n",
        "7. **Conclusion**: The network did not converge to the target output of 1 for the input 0.5 within 2 iterations. This could be due to the small learning rate alpha = 0.1 or the small number of iterations. Increasing the learning rate or the number of iterations may help the network converge faster."
      ],
      "metadata": {
        "id": "1CYAi08DYoEb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktTxRHRxXFLN",
        "outputId": "79dda487-a17f-43df-eb44-aabf46d75f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Error = 0.12496757643413267, Output = 0.5000648513374306\n",
            "Iteration 2: Error = 0.1230528792052934, Output = 0.5039095259828236\n",
            "Final weights: w1 = 1.0001960659546523, w2 = 1.0019640022577905, w3 = 1.0124531681904176\n",
            "Final biases: b1 = -0.49960786809069524, b2 = -0.4960723809940697, b3 = -0.4751001178874611\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "w1, w2, w3 = 1, 1, 1\n",
        "b1, b2, b3 = -0.5, -0.5, -0.5\n",
        "x = 0.5\n",
        "target_output = 1\n",
        "alpha = 0.1\n",
        "num_iterations = 2\n",
        "for i in range(num_iterations):\n",
        "    z1, z2, z3 = w1 * x + b1, w2 * sigmoid(z1) + b2, w3 * sigmoid(z2) + b3\n",
        "    a1, a2, a3 = sigmoid(z1), sigmoid(z2), sigmoid(z3)\n",
        "    error = 0.5 * (target_output - a3) ** 2\n",
        "    delta3, delta2, delta1 = (a3 - target_output) * sigmoid_derivative(z3), delta3 * w3 * sigmoid_derivative(z2), delta2 * w2 * sigmoid_derivative(z1)\n",
        "    w1, w2, w3 = w1 - alpha * delta1 * x, w2 - alpha * delta2 * a1, w3 - alpha * delta3 * a2\n",
        "    b1, b2, b3 = b1 - alpha * delta1, b2 - alpha * delta2, b3 - alpha * delta3\n",
        "    print(f\"Iteration {i+1}: Error = {error}, Output = {a3}\")\n",
        "\n",
        "print(f\"Final weights: w1 = {w1}, w2 = {w2}, w3 = {w3}\")\n",
        "print(f\"Final biases: b1 = {b1}, b2 = {b2}, b3 = {b3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply L1,L2 and elasticNet regularisation to a single-layered neural network with four input nodes and a bias. Assume the input vector has the value [1,2,2,1] and bias = 0 with no activation function at an output node. The learned parameter vector W = [0.25, 0.25, 0.25, 0.25] returns the expected result of \"2.\"**\n",
        "**a) Estimate the total loss using L1 , L2 and Elastic Net regularization separately**\n",
        "**b)  Compare the effects of L1 , L2 and Elastic Net regularization techniques**\n",
        "\n",
        "\n",
        "To apply L1, L2, and Elastic Net regularization to a single-layered neural network, we first need to define the loss function and the regularization terms. The loss function for a regression problem can be defined as the mean squared error (MSE):\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "where N is the number of samples, y_i is the true output, and y_hat is the predicted output.\n",
        "\n",
        "The L1 regularization term is defined as:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "where m is the number of weights, and lambda is the regularization parameter.\n",
        "\n",
        "The L2 regularization term is defined as:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "The Elastic Net regularization term is defined as a combination of L1 and L2 regularization:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "where lambda_1 and lambda_2 are the regularization parameters for L1 and L2 regularization, respectively.\n",
        "\n",
        "Given the input vector [1, 2, 2, 1], the bias b = 0, and the learned parameter vector W = [0.25, 0.25, 0.25, 0.25], we can calculate the total loss using L1, L2, and Elastic Net regularization separately.\n",
        "\n",
        "a) **Estimate the total loss using L1, L2, and Elastic Net regularization separately**:\n",
        "\n",
        "1. **L1 Regularization**:\n",
        "   - m = 4 (number of weights)\n",
        "   - lambda = 0.1 (regularization parameter)\n",
        "   - L1 = 0.1 X (|0.25| + |0.25| + |0.25| + |0.25|) = 0.1 X 1 = 0.1\n",
        "   - MSE = 1/N sum_{i=1}->{N} (y_i - \\hat{y}_i)^2 = 1/1 X (2 - 0.25)^2 = 3.0625\n",
        "   - Total Loss with L1 Regularization: 3.0625 + 0.1 = 3.1625\n",
        "\n",
        "2. **L2 Regularization**:\n",
        "   - lambda = 0.1 (regularization parameter)\n",
        "   - L2 = 0.1 X (0.25^2 + 0.25^2 + 0.25^2 + 0.25^2) = 0.1 X 0.25 = 0.025\n",
        "   - MSE = 1/N sum_{i=1}->{N} (y_i - \\hat{y}_i)^2 = 1/1 X (2 - 0.25)^2 = 3.0625\n",
        "   - Total Loss with L2 Regularization: 3.0625 + 0.025 = 3.0875\n",
        "\n",
        "3. **Elastic Net Regularization**:\n",
        "   - lambda_1 = 0.1 (regularization parameter for L1)\n",
        "   - lambda_2 = 0.1 (regularization parameter for L2)\n",
        "   - Elastic Net = 0.1 X (|0.25| + |0.25| + |0.25| + |0.25|) + 0.1 \\times (0.25^2 + 0.25^2 + 0.25^2 + 0.25^2) = 0.1 \\times 1 + 0.1 X 0.25 = 0.125\n",
        "   - MSE = 1/N \\sum_{i=1}->{N} (y_i - \\hat{y}_i)^2 = 1/1 X (2 - 0.25)^2 = 3.0625\n",
        "   - Total Loss with Elastic Net Regularization: 3.0625 + 0.125 = 3.1875\n",
        "\n",
        "b) **Compare the effects of L1, L2, and Elastic Net regularization techniques**:\n",
        "\n",
        "- L1 Regularization: Encourages sparsity in the weights (some weights become zero), which can help with feature selection and interpretability. However, it may not work well if all features are important.\n",
        "- L2 Regularization: Penalizes large weights, which can help prevent overfitting and improve generalization. It does not encourage sparsity.\n",
        "- Elastic Net Regularization: Combines the benefits of L1 and L2 regularization. It encourages sparsity while also penalizing large weights.\n",
        "\n",
        "In this example, the total loss with L1 regularization is the highest, followed by Elastic Net regularization, and then L2 regularization. This is because L1 regularization penalizes all weights equally, while L2 regularization penalizes large weights more. Elastic Net regularization combines both penalties. The choice of regularization technique depends on the specific problem and the desired properties of the learned model."
      ],
      "metadata": {
        "id": "vbQlJVDyfsmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([1, 2, 2, 1])\n",
        "bias = 0\n",
        "W = np.array([0.25, 0.25, 0.25, 0.25])\n",
        "y = 2\n",
        "y_hat = np.dot(X, W) + bias\n",
        "MSE = (y - y_hat) ** 2\n",
        "lambda_L1 = 0.1\n",
        "lambda_L2 = 0.1\n",
        "L1 = lambda_L1 * np.sum(np.abs(W))\n",
        "L2 = lambda_L2 * np.sum(W ** 2)\n",
        "Elastic_Net = L1 + L2\n",
        "total_loss_L1 = MSE + L1\n",
        "total_loss_L2 = MSE + L2\n",
        "total_loss_Elastic_Net = MSE + Elastic_Net\n",
        "print(f\"MSE: {MSE}\")\n",
        "print(f\"L1 Regularization: {L1}\")\n",
        "print(f\"L2 Regularization: {L2}\")\n",
        "print(f\"Elastic Net Regularization: {Elastic_Net}\")\n",
        "print(f\"Total Loss with L1 Regularization: {total_loss_L1}\")\n",
        "print(f\"Total Loss with L2 Regularization: {total_loss_L2}\")\n",
        "print(f\"Total Loss with Elastic Net Regularization: {total_loss_Elastic_Net}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6TrusdWf8Cx",
        "outputId": "ac691ff0-3028-4ac4-bd6e-fa2c70e7bdee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.25\n",
            "L1 Regularization: 0.1\n",
            "L2 Regularization: 0.025\n",
            "Elastic Net Regularization: 0.125\n",
            "Total Loss with L1 Regularization: 0.35\n",
            "Total Loss with L2 Regularization: 0.275\n",
            "Total Loss with Elastic Net Regularization: 0.375\n"
          ]
        }
      ]
    }
  ]
}